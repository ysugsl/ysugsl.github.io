<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>DAN_V1 | Sober</title><meta name="author" content="ShuangLong Gong"><meta name="copyright" content="ShuangLong Gong"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="DAN_V1Unfolding the Alternating Optimization for Blind Super Resolution[TOC] Abstract&amp;emsp;&amp;emsp;以前的方法将盲超分辨率（SR）问题分解为两个顺序步骤：i）从给定的低分辨率（LR）图像中估计模糊核和ii）基于估计的核恢复SR图像。这两个步骤的解决方案涉及两个独立训练的模型，它们可能不太兼容。第一步的小估">
<meta property="og:type" content="article">
<meta property="og:title" content="DAN_V1">
<meta property="og:url" content="http://example.com/2023/08/14/DAN-V1/index.html">
<meta property="og:site_name" content="Sober">
<meta property="og:description" content="DAN_V1Unfolding the Alternating Optimization for Blind Super Resolution[TOC] Abstract&amp;emsp;&amp;emsp;以前的方法将盲超分辨率（SR）问题分解为两个顺序步骤：i）从给定的低分辨率（LR）图像中估计模糊核和ii）基于估计的核恢复SR图像。这两个步骤的解决方案涉及两个独立训练的模型，它们可能不太兼容。第一步的小估">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/assets/head.jpg">
<meta property="article:published_time" content="2023-08-13T16:00:00.000Z">
<meta property="article:modified_time" content="2023-08-13T16:00:00.000Z">
<meta property="article:author" content="ShuangLong Gong">
<meta property="article:tag" content="Deep Learning; C ++">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/assets/head.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2023/08/14/DAN-V1/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'DAN_V1',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-08-14 00:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.min.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/assets/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">16</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电源</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友联</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Sober"><span class="site-name">Sober</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电源</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友联</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">DAN_V1</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-08-13T16:00:00.000Z" title="发表于 2023-08-14 00:00:00">2023-08-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-08-13T16:00:00.000Z" title="更新于 2023-08-14 00:00:00">2023-08-14</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>17分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="DAN_V1"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="DAN-V1"><a href="#DAN-V1" class="headerlink" title="DAN_V1"></a>DAN_V1</h1><h1 id="Unfolding-the-Alternating-Optimization-for-Blind-Super-Resolution"><a href="#Unfolding-the-Alternating-Optimization-for-Blind-Super-Resolution" class="headerlink" title="Unfolding the Alternating Optimization for Blind Super Resolution"></a>Unfolding the Alternating Optimization for Blind Super Resolution</h1><p>[TOC]</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>&emsp;&emsp;以前的方法将盲超分辨率（SR）问题分解为两个顺序步骤：i）从给定的低分辨率（LR）图像中估计模糊核和ii）基于估计的核恢复SR图像。这两个步骤的解决方案涉及两个独立训练的模型，它们可能不太兼容。第一步的小估计误差可能会导致第二步的性能严重下降。另一方面，第一步只能利用来自LR图像的有限信息，这使得预测高精度模糊核变得困难。针对这些问题，我们采用交替优化算法，而不是分别考虑这两个步骤，它可以在单个模型中估计模糊核并恢复SR图像。具体来说，我们设计了两个卷积神经模块，即Restorer和Estimator。Restorer基于预测的核恢复SR图像，而Estimator在恢复的SR图像的帮助下估计模糊核。我们交替使用这两个模块，并展开这个过程以形成一个端到端可训练的网络。这样，Estimator利用来自LR和SR图像的信息，使模糊核的估计更容易。更重要的是，Restorer是使用Estimator估计的核进行训练的，而不是使用真实的核，因此Restorer对Estimator的估计误差更加容忍。在合成数据集和真实世界图像上进行的大量实验表明，我们的模型可以大大优于最先进的方法，并以更高的速度产生更具视觉效果的结果。源代码可在<a target="_blank" rel="noopener" href="https://github.com/greatlog/DAN.git%E4%B8%8A%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/greatlog/DAN.git上获得。</a></p>
<h2 id="1-emsp-Introduction"><a href="#1-emsp-Introduction" class="headerlink" title="1&emsp;Introduction"></a>1&emsp;Introduction</h2><p>&emsp;&emsp;单张图像超分辨率（SISR）旨在恢复给定降质低分辨率（LR）图像的高分辨率（HR）版本。它在视频增强、医学成像以及安全和监视成像等方面具有广泛的应用。从数学上讲，降质过程可以表示为：<br>$$\mathbf{y}&#x3D;(\mathbf{x}\otimes\mathbf{k})\downarrow_s\mathbf{+n}\tag{1}$$<br>&emsp;&emsp;其中，$x$是原始的HR图像，$y$是降质的LR图像，$⊗$表示$x$与模糊核$k$的二维卷积，$n$表示加性白噪声（AWGN），而$↓s$表示标准的$s$倍下采样器，即仅保留每个不同的$s×s$块的左上像素[35]。因此，SISR指的是从$y$中恢复$x$的过程。由于这种反向特性，它是一个高度不适定的问题，因此一直是一个具有挑战性的任务。<br>&emsp;&emsp;最近，深度神经网络（DNN）在SISR方面取得了显著的成果。但是，这些方法中的大多数[39、2、40、23、8、21]假设模糊核预定义为双三次插值的核。通过这种方式，可以手动合成大量的训练样本，并进一步用于训练功能强大的DNN。然而，在实际应用中，模糊核要复杂得多，而双三次合成的训练样本与真实图像之间存在域差异。这种域差异会导致这些网络在应用于真实应用时性能严重下降。因此，应该更加关注在未知模糊核的情况下进行SR，即盲SR。<br>&emsp;&emsp;在盲SR中，还有一个未确定的变量，即模糊核$k$，优化也变得更加困难。为了使这个问题更容易解决，先前的方法[37、32、38、35]通常将其分解为两个顺序步骤：i）从LR图像估计模糊核；ii）基于估计的核恢复SR图像。这个两步解决方案涉及到两个独立训练的模型，因此它们可能彼此不兼容。第一步的小估计误差可能会导致后续步骤的性能严重下降[14]。但是另一方面，第一步只能利用来自LR图像的有限信息，这使得难以预测高度精确的模糊核。因此，尽管这两个模型都可以单独表现良好，但当它们结合在一起时，最终结果可能是次优的。<br>&emsp;&emsp;我们采用一种交替优化算法，不是将这两个步骤分别考虑，而是在同一个模型中估计模糊核$k$并恢复SR图像$x$。具体来说，我们设计了两个卷积神经模块，即Restorer和Estimator。Restorer基于Estimator预测的模糊核恢复SR图像，恢复的SR图像进一步用于帮助Estimator更好地估计模糊核。一旦手动初始化了模糊核，这两个模块就可以很好地相互配合形成一个封闭循环，可以反复迭代。迭代过程被展开为端到端可训练的网络，称为深度交替网络（DAN）。通过这种方式，Estimator可以利用LR和SR图像的信息，使得模糊核的估计更加容易。更重要的是，Restorer是使用Estimator估计的模糊核进行训练的，而不是使用真实的模糊核。因此，在测试过程中，Restorer对Estimator的估计误差更加容忍。此外，在迭代过程中，两个模块的结果都可以得到显著的改进，因此我们的交替优化算法可能比直接的两步解决方案获得更好的最终结果。我们将我们的贡献总结为三个要点：<br>&emsp;&emsp;    1. 我们采用一种交替优化算法，通过一个单一的网络（DAN）来估计模糊核并恢复SR图像，这有助于两个模块相互兼容，并且可能比先前的两步解决方案获得更好的最终结果。<br>&emsp;&emsp;    2. 我们设计了两个卷积神经模块，可以交替重复使用，然后展开成端到端可训练的网络，没有任何预处理或后处理。这种方法比以前的两步解决方案更容易训练，速度更快。据我们所知，所提出的方法是盲SR的第一个端到端网络。<br>&emsp;&emsp;    3. 在合成数据集和真实世界图像上进行的广泛实验表明，我们的模型可以大大优于最先进的方法，并以更高的速度产生更具视觉效果的结果。</p>
<h2 id="2-emsp-Related-Work"><a href="#2-emsp-Related-Work" class="headerlink" title="2&emsp;Related Work"></a>2&emsp;Related Work</h2><h3 id="2-1-emsp-在双三次插值的情况下的超分辨率"><a href="#2-1-emsp-在双三次插值的情况下的超分辨率" class="headerlink" title="2.1&emsp;在双三次插值的情况下的超分辨率"></a>2.1&emsp;在双三次插值的情况下的超分辨率</h3><p>&emsp;&emsp;针对SISR的基于学习的方法通常需要大量成对的HR和LR图像作为训练样本。然而，在现实世界中很难获取这些成对样本。因此，研究人员通过预定义的下采样设置从HR图像手动合成LR图像。最流行的设置是双三次插值，即在公式1中定义k为双三次插值核。从SRCNN [9]的出现开始，基于这种设置提出了各种DNN [21、40、39、10、16、18]。最近，在RCAN [39]和RRDB [30]的提出之后，这些非盲方法在常见的基准数据集上的性能甚至开始饱和。然而，真实图像的模糊核确实更加复杂。在实际应用中，核是未知的，而且各不相同。因此，尽管这些方法在双三次下采样的情况下表现出色，但由于存在域差异，它们仍然不能直接应用于真实图像。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../assets/%E8%AE%BA%E6%96%87/FILES/DAN_V1.md/img-20230531111454.png" alt="Img"></p>
<h3 id="2-2-emsp-多重降级情况下的超分辨率"><a href="#2-2-emsp-多重降级情况下的超分辨率" class="headerlink" title="2.2&emsp;多重降级情况下的超分辨率"></a>2.2&emsp;多重降级情况下的超分辨率</h3><p>&emsp;&emsp;另一种非盲超分辨率方法旨在针对多种降级提出一个单一模型，即盲SR的两步解决方案中的第二步。这些方法将LR图像及其相应的模糊核作为输入。在[13、29]中，使用模糊核对图像进行下采样和合成训练样本，以便为给定的核和LR图像训练特定模型。在[37]中，直接将模糊核和LR图像连接到DNN的第一层。因此，SR结果可以与LR图像和模糊核密切相关。在[38]中，张等人提出了一种基于ADMM算法的方法。他们将这个问题解释为MAP优化，交替解决数据项和先验项。在[14]中，提出了一种空间特征变换（SFT）层，以更好地保留LR图像中的细节，同时将模糊核作为附加输入。然而，正如[14]所指出的，这些方法的SR结果通常对提供的模糊核非常敏感。提供的核与真实模糊核之间的微小偏差会导致这些非盲超分辨率方法的性能严重下降。</p>
<h3 id="2-3-emsp-盲超分辨率"><a href="#2-3-emsp-盲超分辨率" class="headerlink" title="2.3&emsp; 盲超分辨率"></a>2.3&emsp; 盲超分辨率</h3><p>&emsp;&emsp;以前的盲超分辨率方法通常是核估计方法和非盲超分辨率方法的顺序组合。因此，核估计方法也是盲超分辨率的重要组成部分。在[26]中，Michaeli等人利用内部补丁重复来估计模糊核。在[3]和[5]中，LR图像首先通过生成网络进行下采样，然后使用鉴别器验证下采样图像是否与原始LR图像具有相同的分布。通过这种方式，可以通过生成网络学习到模糊核。在[14]中，Gu等人不仅训练了一个用于核估计的网络，还提出了一个纠正网络来迭代地修正核。尽管估计核的准确性大大提高了，但需要训练两个甚至三个网络，这相当复杂。相比之下，DAN是一个可以进行端到端训练的网络，更容易训练且速度更快。</p>
<h2 id="3-emsp-端到端盲超分"><a href="#3-emsp-端到端盲超分" class="headerlink" title="3&emsp;端到端盲超分"></a>3&emsp;端到端盲超分</h2><h3 id="3-1-emsp-问题描述"><a href="#3-1-emsp-问题描述" class="headerlink" title="3.1&emsp; 问题描述"></a>3.1&emsp; 问题描述</h3><p>&emsp;&emsp;在盲超分问题中，如公式1所示，需要确定三个变量，即x、k和n。在文献中，我们可以首先应用去噪算法[36, 7, 15]。然后，盲超分算法只需要专注于解决k和x。这可以被数学地表达为一个优化问题：<br>$$\underset{\mathbf{k},\mathbf{x}}{\operatorname{arg}\min}|\mathbf{y}-(\mathbf{x}\otimes\mathbf{k})\downarrow_s|<em>1+\phi(\mathbf{x}) \tag{2}$$<br>&emsp;&emsp;其中前一部分是重建项，$\phi(x)$是HR图像的先验项。先验项通常是未知的，很难通过解析方式表达。因此，直接解决这个问题非常困难。先前的方法将这个问题分解成两个连续的步骤：<br>$$\begin{cases}\mathbf{k}&#x3D;M(\mathbf{y})\ \mathbf{x}&#x3D; \underset{\mathbf{k},\mathbf{x}} {\operatorname{arg}\min}|\mathbf{y}-(\mathbf{x}\otimes\mathbf{k})\downarrow</em>{s}||_1+\phi(\mathbf{x})\ \end{cases}\tag{3}$$</p>
<p>&emsp;&emsp;其中，$M(·)$表示从$y$估计$k$的函数，第二步通常通过第2.2节中描述的非盲超分方法来解决。这种两步解决方案有三个缺点。首先，该算法通常需要训练两个甚至更多的模型，这相当复杂。其次，$M(·)$只能利用$y$中的信息，将$k$视为$y$的一种先验。但实际上，没有来自$x$的信息，$k$就不能被正确地解决。最后，第二步的非盲超分模型是使用ground-truth核进行训练的。然而，在测试期间，它只能访问在第一步中估计的核。地面真实核与估计核之间的差异通常会导致非盲超分模型的性能大幅下降[14]。<br>&emsp;&emsp;针对这些缺点，我们提出了一种端到端网络，可以大大解决这些问题。我们仍然将其分成两个子问题，但是我们不是按顺序解决它们，而是采用交替优化算法，交替恢复SR图像并估计相应的模糊核。其数学表达式为：<br>$$\begin{cases}\mathbf{k}_{i+1}&#x3D;\underset{\mathbf{k}}{\operatorname{arg}\min}|\mathbf{y}-(\mathbf{x}_i\otimes\mathbf{k})\downarrow_s|<em>1\ \mathbf{x}</em>{i+1}&#x3D;\underset{\mathbf{x}}{\operatorname{arg}\min}|\mathbf{y}-(\mathbf{x}\otimes\mathbf{k}_i)\downarrow_s|_1+\phi(\mathbf{x})\end{cases}\tag{4}$$<br>&emsp;&emsp;我们通过卷积神经网络模块Estimator和Restorer交替解决这两个子问题。实际上，Estimator甚至有一个解析解。但是我们在实验中发现，解析解更耗时，而且不够健壮（当噪声没有完全去除时）。我们将迭代次数固定为$T$，并展开迭代过程，形成一个端到端可训练的网络，称为深交替网络（DAN）。<br>&emsp;&emsp;如图1所示，我们通过狄拉克函数来初始化核，即核的中心为1，其他为0。类似于[14, 37]的方法，核也被重塑并通过主成分分析（PCA）进行降维。我们在实践中将T设置为4，两个模块仅在最后一次迭代时受到L1损失的监督。整个网络可以很好地训练，因为两个模块的参数在不同迭代之间共享，没有对中间结果施加任何限制。<br>&emsp;&emsp;在DAN中，Estimator将LR和SR图像作为输入，这使得模糊核$k$的估计更容易。更重要的是，Restorer是使用Estimator估计的核进行训练的，而不是像先前的方法那样使用ground-truth核。因此，在测试期间，Restorer可以更容忍Estimator的估计误差。此外，与先前的两步解决方案相比，DAN中两个模块的结果都可以得到显著的改善，DAN很可能获得更好的最终结果。特别是，在缩放因子$s &#x3D; 1$的情况下，DAN变成了一个去模糊网络。由于篇幅有限，本文仅讨论SR情况。</p>
<h3 id="3-2-emsp-实例化卷积神经网络模块"><a href="#3-2-emsp-实例化卷积神经网络模块" class="headerlink" title="3.2&emsp;实例化卷积神经网络模块"></a>3.2&emsp;实例化卷积神经网络模块</h3><p>&emsp;&emsp;我们网络中的两个模块都有两个输入。Estimator采用LR图像和SR图像，Restorer采用LR图像和模糊核作为输入。我们将LR图像定义为基本输入，另一个输入是条件输入。例如，模糊核是Restorer的条件输入。在迭代过程中，两个模块的基本输入保持不变，但它们的条件输入会被重复更新。我们认为，将每个模块的输出与其条件输入密切相关非常重要。否则，迭代结果将在第一次迭代时崩溃为一个固定点。具体来说，如果Estimator无论SR图像的值如何输出相同的核，或者Restorer无论模糊核的值如何输出相同的SR图像，它们的输出将仅取决于基本输入，并且结果将在迭代过程中保持不变。<br>&emsp;&emsp;为了确保Estimator和Restorer的输出与它们的条件输入密切相关，我们提出了一个条件残差块（CRB）。在[39]中的残差块的基础上，我们在开头连接条件和基本输入：<br>$$f_{out}&#x3D;R(Concat([f_{basic},f_{cond}]))+f_{basic}\tag{5}$$<br>&emsp;&emsp;其中，$R(·)$表示CRB的残差映射函数，$Concat([·, ·])$表示连接操作。$fbasic$和$fcond$分别是基本输入和条件输入。如图2(c)所示，残差映射函数由两个3×3卷积层和一个通道注意力层[17]组成。Estimator和Restorer都是由CRB构建的。<br>&emsp;&emsp;<strong>Estimator。</strong> Estimator的整个结构如图2（b）所示。我们首先通过带有步幅s的卷积层对SR图像进行下采样。然后将特征图作为条件输入发送给所有的CRB。在网络的末端，我们通过全局平均池化来压缩特征，形成预测核的元素。由于核是通过PCA降维的，Estimator只需要估计模糊核的PCA结果。在实践中，Estimator有5个CRB，每个CRB的基本输入和条件输入都有32个通道。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../assets/%E8%AE%BA%E6%96%87/FILES/DAN_V1.md/img-20230601161517.png" alt="Img"><br>&emsp;&emsp;<strong>Restorer。</strong> Restorer的整个结构如图2（a）所示。在Restorer中，我们将核在空间维度上拉伸到与LR图像相同的空间大小。然后将拉伸后的核作为条件输入发送给Restorer的所有CRB。我们使用PixelShuffle [28]层将特征放大到所需的尺寸。在实践中，Restorer有40个CRB，每个CRB的基本输入和条件输入分别有64个和10个通道。</p>
<h2 id="四、实验"><a href="#四、实验" class="headerlink" title="四、实验"></a>四、实验</h2><h3 id="4-1-合成测试图像实验"><a href="#4-1-合成测试图像实验" class="headerlink" title="4.1 合成测试图像实验"></a>4.1 合成测试图像实验</h3><h4 id="4-1-1-数据，训练和测试"><a href="#4-1-1-数据，训练和测试" class="headerlink" title="4.1.1 数据，训练和测试"></a>4.1.1 数据，训练和测试</h4><p>&emsp;&emsp;我们从DIV2K [1]和Flickr2K [11]收集了3450个HR图像作为训练集。为了与其他方法进行合理比较，我们使用两种不同的退化设置来训练模型。一种是[14]中的设置，它仅关注具有各向同性高斯模糊核的情况。另一种是[3]中的设置，它关注具有更一般和不规则的模糊核的情况。<br>&emsp;&emsp;<strong>设置1。</strong> 遵循[14]中的设置，核大小设置为21。在训练过程中，对于缩放因子4、3和2，核宽度在[0.2，4.0]、[0.2，3.0]和[0.2，2.0]中均匀采样。对于定量评估，我们从常用的基准数据集Set5 [4]、Set14 [34]、Urban100 [19]、BSD100 [24]和Manga109 [25]中收集HR图像。由于为了进行合理的比较需要确定的核，我们从范围[1.8，3.2]、[1.35，2.40]和[0.80，1.60]中均匀选择8个核，分别表示缩放因子4、3和2。HR图像首先由选定的模糊核进行模糊处理，然后进行下采样，形成合成测试图像。<br>&emsp;&emsp;<strong>设置2。</strong> 遵循[3]中的设置，我们将核大小设置为11。我们首先生成各向异性高斯核。两个轴的长度均匀分布在（0.6，5）之间，并旋转一个均匀分布在[−π，π]之间的随机角度。为了偏离正常的高斯分布，我们进一步应用均匀乘性噪声（最多为每个像素值的25%），并将其归一化为总和为1。对于测试，我们使用[3]中使用的基准数据集DIV2KRK。<br>&emsp;&emsp;训练期间所有缩放因子的输入尺寸为64×64。批量大小为64。每个模型训练4×105次迭代。我们使用Adam [22]作为优化器，其中β1 &#x3D; 0.9，β2 &#x3D; 0.99。初始学习率为2×10-4，并在每1×105次迭代时衰减一半。所有模型都在RTX2080Ti GPU上训练。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../assets/%E8%AE%BA%E6%96%87/FILES/DAN_V1.md/img-20230601173941.png" alt="Img"></p>
<h4 id="4-1-2-定性结果"><a href="#4-1-2-定性结果" class="headerlink" title="4.1.2 定性结果"></a>4.1.2 定性结果</h4><p>&emsp;&emsp;<strong>设置1。</strong> 对于第一个设置，我们在由Gaussian8核合成的测试图像上评估我们的方法。我们主要将结果与设计用于盲SR的ZSSR [29]和IKC [14]进行比较。我们还包括与CARN [2]的比较。由于它不是为盲SR设计的，我们在CARN之前或之后执行去模糊方法[27]。在转换后的YCbCr空间的Y通道上，PSNR和SSIM结果如表1所示。<br>&emsp;&emsp;尽管CARN在双三次下采样的情况下取得了显着的结果，但当应用于具有未知模糊核的图像时，其性能会严重下降。当CARN后跟去模糊方法时，其性能得到了很大的改善，但仍然不如盲SR方法。ZSSR利用内部补丁重复对每个单独测试图像训练特定的网络。然而，ZSSR具有天生的缺陷：每个图像的训练样本是有限的，因此它无法为HR图像学习良好的先验知识。IKC也是盲SR的两步解决方案。尽管在IKC中估计的核的准确性得到了很大的提高，但最终结果仍然不理想。DAN在端到端方案中进行训练，这不仅比两步解决方案容易训练得多，而且还有可能达到更好的最优点。如表1所示，DAN在Manga109的三倍尺度上的PSNR结果甚至比IKC高4.95dB。对于其他尺度和数据集，DAN也大大优于IKC。<br>&emsp;&emsp;为了进行比较，我们展示了Urban100数据集中图像005的视觉结果，如图3所示。可以看出，CARN和ZSSR甚至无法恢复窗户的边缘。IKC表现更好，但边缘严重模糊。而DAN可以恢复锐利的边缘，并产生更加视觉上愉悦的结果。<br>&emsp;&emsp;<strong>设置2。</strong> 第二个设置涉及不规则模糊核，这更一般，但也更难解决。对于设置2，我们主要比较三种不同类别的方法：i）在双三次下采样的图像上训练的SOTA SR算法，如EDSR [23]和RCAN [39]，ii）为NTIRE竞赛设计的盲SR方法，如PDN [31]和WDSR [33]，iii）两步解决方案，即核估计方法和非盲SR方法的组合，如Kernel-GAN [3]和ZSSR [29]。在Y通道上的PSNR和SSIM结果如表2所示。<br>&emsp;&emsp;类似地，训练在双三次下采样的图像上的方法的性能受到域差异的限制。因此，它们的结果仅比插值略好。类别2中的方法是在NTIRE竞赛提供的合成图像上进行训练的。尽管这些方法在竞赛中取得了显着的成果，但它们仍然无法很好地推广到不规则模糊核。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../assets/%E8%AE%BA%E6%96%87/FILES/DAN_V1.md/img-20230601174407.png" alt="Img"><br>&emsp;&emsp;对比类别3的方法可以让我们受益匪浅。具体来说，当提供GT核时，USRNet [35]取得了显着的结果，并且KernelGAN在核估计方面的表现也很好。然而，如表2所示，当它们结合在一起时，最终的SR结果比大多数其他方法还要差。这表明Estimator和Restorer之间的兼容性非常重要。此外，尽管更好的核估计方法可以提高SR结果，但总体性能仍然远不如DAN。对于尺度×2和×4，DAN的表现优于KernelGAN和ZSSR的组合分别为2.20dB和0.74dB。<br>&emsp;&emsp;我们展示了DIVKRK数据集中图像892的视觉结果，如图4所示。虽然KernelGAN和ZSSR的组合可以比插值产生稍微更锐利的边缘，但它会受到严重的伪影的影响。DAN的SR图像明显更加清晰，具有更可靠的细节。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../assets/%E8%AE%BA%E6%96%87/FILES/DAN_V1.md/img-20230601174515.png" alt="Img"></p>
<h4 id="4-1-3-估计核研究"><a href="#4-1-3-估计核研究" class="headerlink" title="4.1.3 估计核研究"></a>4.1.3 估计核研究</h4></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://example.com">ShuangLong Gong</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2023/08/14/DAN-V1/">http://example.com/2023/08/14/DAN-V1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Sober</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/assets/head.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/08/14/CDCN/" title="CDCN"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">CDCN</div></div></a></div><div class="next-post pull-right"><a href="/2023/08/14/DSSR/" title="DSSR"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">DSSR</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/assets/head.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">ShuangLong Gong</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">16</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ysugsl"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ysugsl" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:sober0306@foxmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Welcome to my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#DAN-V1"><span class="toc-text">DAN_V1</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Unfolding-the-Alternating-Optimization-for-Blind-Super-Resolution"><span class="toc-text">Unfolding the Alternating Optimization for Blind Super Resolution</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-emsp-Introduction"><span class="toc-text">1 Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-emsp-Related-Work"><span class="toc-text">2 Related Work</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-emsp-%E5%9C%A8%E5%8F%8C%E4%B8%89%E6%AC%A1%E6%8F%92%E5%80%BC%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%E7%9A%84%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87"><span class="toc-text">2.1 在双三次插值的情况下的超分辨率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-emsp-%E5%A4%9A%E9%87%8D%E9%99%8D%E7%BA%A7%E6%83%85%E5%86%B5%E4%B8%8B%E7%9A%84%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87"><span class="toc-text">2.2 多重降级情况下的超分辨率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-emsp-%E7%9B%B2%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87"><span class="toc-text">2.3  盲超分辨率</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-emsp-%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9B%B2%E8%B6%85%E5%88%86"><span class="toc-text">3 端到端盲超分</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-emsp-%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0"><span class="toc-text">3.1  问题描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-emsp-%E5%AE%9E%E4%BE%8B%E5%8C%96%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9D%97"><span class="toc-text">3.2 实例化卷积神经网络模块</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%AE%9E%E9%AA%8C"><span class="toc-text">四、实验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E5%90%88%E6%88%90%E6%B5%8B%E8%AF%95%E5%9B%BE%E5%83%8F%E5%AE%9E%E9%AA%8C"><span class="toc-text">4.1 合成测试图像实验</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-1-%E6%95%B0%E6%8D%AE%EF%BC%8C%E8%AE%AD%E7%BB%83%E5%92%8C%E6%B5%8B%E8%AF%95"><span class="toc-text">4.1.1 数据，训练和测试</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-2-%E5%AE%9A%E6%80%A7%E7%BB%93%E6%9E%9C"><span class="toc-text">4.1.2 定性结果</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-3-%E4%BC%B0%E8%AE%A1%E6%A0%B8%E7%A0%94%E7%A9%B6"><span class="toc-text">4.1.3 估计核研究</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/14/BSRGAN/" title="BSRGAN">BSRGAN</a><time datetime="2023-08-13T16:00:00.000Z" title="发表于 2023-08-14 00:00:00">2023-08-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/14/CDCN/" title="CDCN">CDCN</a><time datetime="2023-08-13T16:00:00.000Z" title="发表于 2023-08-14 00:00:00">2023-08-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/14/DAN-V1/" title="DAN_V1">DAN_V1</a><time datetime="2023-08-13T16:00:00.000Z" title="发表于 2023-08-14 00:00:00">2023-08-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/14/DSSR/" title="DSSR">DSSR</a><time datetime="2023-08-13T16:00:00.000Z" title="发表于 2023-08-14 00:00:00">2023-08-14</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/08/14/CMOS/" title="CMOS">CMOS</a><time datetime="2023-08-13T16:00:00.000Z" title="发表于 2023-08-14 00:00:00">2023-08-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By ShuangLong Gong</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="30" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v6.2.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.3.1" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><!-- hexo injector body_end end --></body></html>